# -*- coding: utf-8 -*-
import os
import cv2
import torch
import pickle
import numpy as np
from PIL import Image, ImageDraw, ImageFont

# Detectron2 imports
from detectron2.data import MetadataCatalog
from detectron2.checkpoint import DetectionCheckpointer
from detectron2.modeling import build_model
import detectron2.data.transforms as T

# AdelaiDet imports
from adet.config import get_cfg as get_adet_cfg
# from adet.data.augmentation import Pad
from ultralytics import YOLO
# --- è¨­å®šåƒæ•¸ ---
CONFIG_FILE = "configs/r_50/rects/pretrain.yaml"
MODEL_WEIGHTS = "res50_pretrain_synch-art-lsvt-rects.pth"
INPUT_IMAGE = "data/20251125153149.jpeg"  # è«‹ç¢ºèªæª”å
OUTPUT_IMAGE = "data/result_chinese_test.jpg"
CHN_CLS_LIST_PATH = "chn_cls_list"
FONT_PATH = "simsun.ttc"
OUTPUT_BASE_DIR = "data/output" # *** ä¿®æ”¹è¼¸å‡ºåŸºç¤ç›®éŒ„ ***
if not os.path.exists(FONT_PATH):
    FONT_PATH = "font/Arial-Unicode-MS.ttf"

class SimplePadTransform:
    def __init__(self, top, bottom, left, right):
        self.top = top
        self.bottom = bottom
        self.left = left
        self.right = right

    def apply_image(self, img):
        return cv2.copyMakeBorder(
            img,
            self.top, self.bottom,
            self.left, self.right,
            borderType=cv2.BORDER_CONSTANT,
            value=(0, 0, 0)
        )


class SimplePad:
    def __init__(self, divisible_size=32):
        self.divisible_size = divisible_size

    def get_transform(self, image):
        h, w = image.shape[:2]
        div = self.divisible_size

        new_h = int(np.ceil(h / div) * div)
        new_w = int(np.ceil(w / div) * div)

        pad_h = new_h - h
        pad_w = new_w - w

        return SimplePadTransform(0, pad_h, 0, pad_w)

class DeepSoloPredictor:
    """
    åŸºæ–¼ DeepSolo å®˜æ–¹ predictor.py ä¿®æ”¹çš„é æ¸¬å™¨ã€‚
    ç¢ºä¿åŒ…å« Resize å’Œ Pad æ“ä½œï¼Œä»¥æ”¯æ´ ViTAE å’Œ Transformer æ¶æ§‹ã€‚
    """
    def __init__(self, cfg):
        self.cfg = cfg.clone()
        self.model = build_model(self.cfg)
        self.model.eval()

        if len(cfg.DATASETS.TEST):
            self.metadata = MetadataCatalog.get(cfg.DATASETS.TEST[0])

        checkpointer = DetectionCheckpointer(self.model)
        checkpointer.load(cfg.MODEL.WEIGHTS)

        # é€™æ˜¯é—œéµï¼šDeepSolo éœ€è¦å°‡åœ–ç‰‡ Resize ä¸¦ Pad åˆ° 32 çš„å€æ•¸
        self.aug = T.ResizeShortestEdge(
            [cfg.INPUT.MIN_SIZE_TEST, cfg.INPUT.MIN_SIZE_TEST], cfg.INPUT.MAX_SIZE_TEST
        )
        self.pad = SimplePad(divisible_size=32)

        self.input_format = cfg.INPUT.FORMAT
        assert self.input_format in ["RGB", "BGR"], self.input_format

    def __call__(self, original_image):
        """
        Args:
            original_image (np.ndarray): (H, W, C) BGR æ ¼å¼åœ–ç‰‡
        """
        with torch.no_grad():
            if self.input_format == "RGB":
                original_image = original_image[:, :, ::-1]

            height, width = original_image.shape[:2]

            # 1. Resize
            image = self.aug.get_transform(original_image).apply_image(original_image)
            # 2. Pad (é€™ä¸€æ­¥è§£æ±ºäº†ç¶­åº¦å ±éŒ¯çš„å•é¡Œ)
            image = self.pad.get_transform(image).apply_image(image)
            # 3. è½‰æ›ç‚º Tensor (C, H, W)
            image = torch.as_tensor(image.astype("float32").transpose(2, 0, 1))

            inputs = {"image": image, "height": height, "width": width}

            # æ¨¡å‹æ¨è«–
            predictions = self.model([inputs])[0]
            return predictions

def setup_cfg():
    """åˆå§‹åŒ–é…ç½®"""
    cfg = get_adet_cfg() # é€™è£¡ä¸éœ€è¦åƒæ•¸

    # è¼‰å…¥è¨­å®šæª”
    if not os.path.exists(CONFIG_FILE):
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°è¨­å®šæª”: {CONFIG_FILE}")
    cfg.merge_from_file(CONFIG_FILE)

    # è¨­å®šæ¬Šé‡
    if not os.path.exists(MODEL_WEIGHTS):
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°æ¬Šé‡æª”: {MODEL_WEIGHTS}")
    cfg.MODEL.WEIGHTS = MODEL_WEIGHTS

    # è¨­å®šè£ç½®
    cfg.MODEL.DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

    # === é‡è¦ï¼šä¸è¦è¨­å®š FCOS ç›¸é—œé–¾å€¼ï¼Œå› ç‚º DeepSolo æ˜¯ Transformer æ¶æ§‹ ===
    # æˆ‘å€‘åªè¨­å®šé€šç”¨çš„æ¸¬è©¦é–¾å€¼ (å¦‚æœé…ç½®æª”ä¸­æœ‰å®šç¾©)
    if hasattr(cfg.MODEL, "RETINANET"):
        cfg.MODEL.RETINANET.SCORE_THRESH_TEST = 0.3
    if hasattr(cfg.MODEL, "ROI_HEADS"):
        cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.3

    cfg.freeze()
    return cfg

def load_dictionary(dict_path):
    if not os.path.exists(dict_path):
        print(f"è­¦å‘Š: æ‰¾ä¸åˆ°å­—è¡¨ {dict_path}")
        return None
    with open(dict_path, 'rb') as f:
        chars = pickle.load(f)
    return chars

def decode_text(rec, vocab):
    """è§£ç¢¼æ¨¡å‹è¼¸å‡ºçš„ç´¢å¼•åºåˆ—"""
    if vocab is None:
        return str(rec)

    text = ""
    for idx in rec:
        # EOS
        if idx == len(vocab):
            continue

        if 0 <= idx < len(vocab):
            ch = vocab[idx]

            # âœ… è‹¥æ˜¯ int Unicode -> è½‰å­—å…ƒ
            if isinstance(ch, int):
                ch = chr(ch)

            text += ch

    return text

# --- è¼”åŠ©å‡½å¼ï¼šå–å¾—è³‡æ–™å¤¾å…§çš„åœ–ç‰‡æ¸…å–® ---
def get_image_paths(folder_path, valid_extensions=('.jpg', '.jpeg', '.png', '.bmp')):
    """
    æƒææŒ‡å®šè³‡æ–™å¤¾ï¼Œä¸¦è¿”å›æ‰€æœ‰åœ–ç‰‡æª”æ¡ˆçš„å®Œæ•´è·¯å¾‘åˆ—è¡¨ã€‚
    """
    image_list = []
    
    if not os.path.isdir(folder_path):
        print(f"éŒ¯èª¤ï¼šè³‡æ–™å¤¾ '{folder_path}' ä¸å­˜åœ¨ã€‚")
        return image_list

    # éæ­·è³‡æ–™å¤¾ä¸­çš„æ‰€æœ‰æª”æ¡ˆ
    for filename in os.listdir(folder_path):
        # å°‡æª”åè½‰ç‚ºå°å¯«ï¼Œä¸¦æª¢æŸ¥å‰¯æª”åæ˜¯å¦åœ¨æœ‰æ•ˆæ¸…å–®ä¸­
        if filename.lower().endswith(valid_extensions):
            # å»ºç«‹åœ–ç‰‡çš„å®Œæ•´è·¯å¾‘
            full_path = str(os.path.join(folder_path, filename))
            image_list.append(full_path)
            
    return image_list

def main():
    print("æ­£åœ¨åˆå§‹åŒ–ç’°å¢ƒèˆ‡æ¨¡å‹...")
    cfg = setup_cfg()

    # ä½¿ç”¨æˆ‘å€‘è‡ªå®šç¾©çš„ Predictor (åŒ…å« Pad é‚è¼¯)
    predictor = DeepSoloPredictor(cfg)

    vocab = load_dictionary(CHN_CLS_LIST_PATH)
    # 2. è®€å–åœ–ç‰‡
    # DATA_DIR = "data" 
    DATA_DIR = "step2_ship_crops"
    image_list = get_image_paths(DATA_DIR)
    for image in image_list:
        # æ ¹æ“šåœ–ç‰‡è·¯å¾‘ç”Ÿæˆè¼¸å‡ºæª”æ¡ˆå
        # ç¯„ä¾‹ï¼šstep2_ship_crops/image1.jpg -> image1
        base_name = os.path.splitext(os.path.basename(image))[0]
        output_txt_path = os.path.join(OUTPUT_BASE_DIR, f"{base_name}_result.txt")
        output_img_path = os.path.join(OUTPUT_BASE_DIR, f"{base_name}_vis.jpg")

        print(f"\n--- è™•ç†åœ–ç‰‡: {image} ---")
        img = cv2.imread(image)
        if img is None:
            print(f"éŒ¯èª¤: ç„¡æ³•è®€å– {image}ï¼Œè·³éã€‚")
            continue
        
        # é–‹å•Ÿ TXT æª”æ¡ˆæº–å‚™å¯«å…¥
        with open(output_txt_path, 'w', encoding='utf-8') as f_out:
            f_out.write(f"--- åœ–ç‰‡æª”æ¡ˆ: {os.path.basename(image)} ---\n\n")

            print("æ­£åœ¨åŸ·è¡Œæ¨è«– (Inference)...")
            # åŸ·è¡Œæ¨è«–
            outputs = predictor(img)
            
            # æå– CPU ä¸Šçš„å¯¦ä¾‹
            instances = outputs["instances"].to("cpu")
            
            # æº–å‚™ç¹ªåœ–
            img_pil = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
            draw = ImageDraw.Draw(img_pil)
            try:
                font = ImageFont.truetype(FONT_PATH, 24)
            except:
                font = ImageFont.load_default()

            f_out.write("--- è¾¨è­˜çµæœ ---\n")
            
            if instances.has("recs"):
                recs = instances.recs.tolist()
                scores = instances.scores.tolist()

                # è™•ç†é‚Šç•Œæ¡†
                if instances.has("pred_boxes"):
                    boxes = instances.pred_boxes.tensor.numpy()
                else:
                    boxes = None

                for i, rec in enumerate(recs):
                    score = scores[i]
                    if score < 0.3: continue # éæ¿¾ä½åˆ†

                    text = decode_text(rec, vocab)
                    result_line = f"æ–‡å­— {i+1}: {text} (ä¿¡å¿ƒåº¦: {score:.2f})\n"
                    
                    # å¯«å…¥ TXT æª”æ¡ˆ
                    f_out.write(result_line)
                    # è¼¸å‡ºåˆ°çµ‚ç«¯æ©Ÿ
                    print(result_line.strip())

                    # ç¹ªåœ–
                    if boxes is not None:
                        x1, y1, x2, y2 = boxes[i]
                        # ç•«æ¡†
                        draw.rectangle([x1, y1, x2, y2], outline=(0, 255, 0), width=3)
                        # ç•«æ–‡å­—
                        draw.text((x1, y1 - 25), f"{text} ({score:.2f})", font=font, fill=(255, 0, 0))
            
            print(f"âœ… æ–‡å­—çµæœå·²å„²å­˜è‡³: {output_txt_path}")
            
        # å„²å­˜çµæœåœ–ç‰‡
        vis_img = cv2.cvtColor(np.array(img_pil), cv2.COLOR_RGB2BGR)
        cv2.imwrite(output_img_path, vis_img)
        print(f"ğŸ–¼ï¸ è¦–è¦ºåŒ–åœ–ç‰‡å·²å„²å­˜è‡³: {output_img_path}")
        # print(f"è®€å–åœ–ç‰‡: {image}")
        # img = cv2.imread(image)
        # if img is None:
        #     print(f"éŒ¯èª¤: ç„¡æ³•è®€å– {image}")
        #     return


        # print("æ­£åœ¨åŸ·è¡Œæ¨è«– (Inference)...")
        # # åŸ·è¡Œæ¨è«–
        # outputs = predictor(img)
        # # print(outputs)
        # # æå– CPU ä¸Šçš„å¯¦ä¾‹
        # instances = outputs["instances"].to("cpu")
        # fields = instances.get_fields()
        # # print("âœ… OCR å›å‚³æ¬„ä½:", fields.keys())
        # # æº–å‚™ç¹ªåœ–
        # img_pil = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
        # draw = ImageDraw.Draw(img_pil)
        # try:
        #     font = ImageFont.truetype(FONT_PATH, 24)
        # except:
        #     font = ImageFont.load_default()

        # print("\n--- è¾¨è­˜çµæœ ---")
        # if instances.has("recs"):
        #     recs = instances.recs.tolist()
        #     scores = instances.scores.tolist()

        #     # è™•ç†é‚Šç•Œæ¡† (DeepSolo è¼¸å‡ºçš„æ˜¯ Bezier æ›²ç·šæˆ– Boxes)
        #     if instances.has("pred_boxes"):
        #         boxes = instances.pred_boxes.tensor.numpy()
        #     else:
        #         boxes = None

        #     for i, rec in enumerate(recs):
        #         score = scores[i]
        #         if score < 0.3: continue # éæ¿¾ä½åˆ†

        #         text = decode_text(rec, vocab)
        #         print(f"æ–‡å­— {i+1}: {text} (ä¿¡å¿ƒåº¦: {score:.2f})")

        #         # ç¹ªåœ–
        #         if boxes is not None:
        #             x1, y1, x2, y2 = boxes[i]
        #             # ç•«æ¡†
        #             draw.rectangle([x1, y1, x2, y2], outline=(0, 255, 0), width=3)
        #             # ç•«æ–‡å­—
        #             draw.text((x1, y1 - 25), f"{text} ({score:.2f})", font=font, fill=(255, 0, 0))

        # vis_img = cv2.cvtColor(np.array(img_pil), cv2.COLOR_RGB2BGR)
        # cv2.imwrite(OUTPUT_IMAGE, vis_img)
        # print(f"\nçµæœå·²å„²å­˜è‡³: {OUTPUT_IMAGE}")

if __name__ == "__main__":
    main()


